{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdb0c5b-7a27-4751-add1-f9c2d76560f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'precip' (time: 276, latitude: 39, longitude: 36)>\n",
      "[387504 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2023-04-30 2023-05-01 ... 2024-01-30\n",
      "  * latitude   (latitude) float32 -3.075 -3.025 -2.975 ... -1.275 -1.225 -1.175\n",
      "  * longitude  (longitude) float32 29.18 29.22 29.27 29.32 ... 30.82 30.88 30.93\n",
      "Attributes:\n",
      "    colorBarMaximum:  25.0\n",
      "    colorBarMinimum:  0.0\n",
      "    ioos_category:    Meteorology\n",
      "    long_name:        Precipitation\n",
      "    standard_name:    lwe_precipitation_rate\n",
      "    time_step:        day\n",
      "    units:            mm/day\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m shapefile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGit\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRuntime files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLV_Kagera_Akanyaru.shp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     63\u001b[0m output_nc_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_clipped_file.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 65\u001b[0m clipped_ds \u001b[38;5;241m=\u001b[39m clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(clipped_ds)\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36mclip_netcdf_with_shapefile\u001b[1;34m(nc_file, shapefile, output_nc_file)\u001b[0m\n\u001b[0;32m     50\u001b[0m         clipped_data\u001b[38;5;241m.\u001b[39mappend(clipped_array)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Combine the clipped data arrays into a single dataset\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m clipped_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset({var: clipped_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i, var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ds\u001b[38;5;241m.\u001b[39mdata_vars)})\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save the clipped dataset to a new NetCDF file\u001b[39;00m\n\u001b[0;32m     56\u001b[0m clipped_ds\u001b[38;5;241m.\u001b[39mto_netcdf(output_nc_file)\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         clipped_data\u001b[38;5;241m.\u001b[39mappend(clipped_array)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Combine the clipped data arrays into a single dataset\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m clipped_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset({var: clipped_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i, var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ds\u001b[38;5;241m.\u001b[39mdata_vars)})\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save the clipped dataset to a new NetCDF file\u001b[39;00m\n\u001b[0;32m     56\u001b[0m clipped_ds\u001b[38;5;241m.\u001b[39mto_netcdf(output_nc_file)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "\n",
    "# Function to clip the NetCDF file using the shapefile\n",
    "def clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file):\n",
    "    # Load the NetCDF data\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "\n",
    "    # Load the shapefile\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Ensure the shapefile is in the same coordinate reference system (CRS) as the NetCDF data\n",
    "    if 'crs' in ds.attrs:\n",
    "        crs = ds.attrs['crs']\n",
    "        gdf = gdf.to_crs(crs)\n",
    "    \n",
    "    # Extract geometry from shapefile\n",
    "    shapes = [feature[\"geometry\"] for feature in gdf.__geo_interface__[\"features\"]]\n",
    "\n",
    "    # Initialize a list to store the clipped data\n",
    "    clipped_data = []\n",
    "    \n",
    "    # Iterate over variables in the NetCDF file\n",
    "    for var in ds.data_vars:\n",
    "        # Get the data array for the variable\n",
    "        data_array = ds[var]\n",
    "\n",
    "        #\n",
    "        print(data_array)\n",
    "        \n",
    "        # Ensure the data array has spatial dimensions (lat, lon)\n",
    "        if 'lat' in data_array.dims and 'lon' in data_array.dims:\n",
    "            # Create a mask using rasterio\n",
    "            with rasterio.open(nc_file) as src:\n",
    "                out_image, out_transform = mask(src, shapes, crop=True)\n",
    "                out_meta = src.meta.copy()\n",
    "                \n",
    "            # Update the metadata to match the shape of the clipped data\n",
    "            out_meta.update({\"height\": out_image.shape[1],\n",
    "                             \"width\": out_image.shape[2],\n",
    "                             \"transform\": out_transform})\n",
    "            \n",
    "            # Convert the clipped data to an xarray DataArray\n",
    "            clipped_array = xr.DataArray(out_image[0], coords={'lat': data_array['lat'], 'lon': data_array['lon']}, dims=['lat', 'lon'])\n",
    "            \n",
    "            # Append the clipped data array to the list\n",
    "            clipped_data.append(clipped_array)\n",
    "    \n",
    "    # Combine the clipped data arrays into a single dataset\n",
    "    clipped_ds = xr.Dataset({var: clipped_data[i] for i, var in enumerate(ds.data_vars)})\n",
    "    \n",
    "    # Save the clipped dataset to a new NetCDF file\n",
    "    clipped_ds.to_netcdf(output_nc_file)\n",
    "    \n",
    "    return clipped_ds\n",
    "\n",
    "# Example usage\n",
    "nc_file = r'D:\\Git\\Projects\\Runtime files\\chirps20GlobalDailyP05_31cf_9fff_f151.nc'\n",
    "shapefile = 'D:\\Git\\Projects\\Runtime files\\LV_Kagera_Akanyaru.shp'\n",
    "output_nc_file = 'output_clipped_file.nc'\n",
    "\n",
    "clipped_ds = clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file)\n",
    "print(clipped_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f42f2ac-514c-4556-a8e0-f27d7e6e1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "\n",
    "def clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file):\n",
    "    # Load the NetCDF data\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "\n",
    "    # Load the shapefile\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Ensure the shapefile is in the same coordinate reference system (CRS) as the NetCDF data\n",
    "    if 'crs' in ds.attrs:\n",
    "        crs = ds.attrs['crs']\n",
    "        gdf = gdf.to_crs(crs)\n",
    "    \n",
    "    # Extract geometry from shapefile\n",
    "    shapes = [feature[\"geometry\"] for feature in gdf.__geo_interface__[\"features\"]]\n",
    "\n",
    "    clipped_data = {}\n",
    "    \n",
    "    # Iterate over variables in the NetCDF file\n",
    "    for var in ds.data_vars:\n",
    "        data_array = ds[var]\n",
    "        \n",
    "        if 'lat' in data_array.dims and 'lon' in data_array.dims:\n",
    "            # Convert xarray DataArray to a format rasterio can handle\n",
    "            lat = data_array['lat'].values\n",
    "            lon = data_array['lon'].values\n",
    "            values = data_array.values\n",
    "            \n",
    "            # Define affine transform for the data array\n",
    "            transform = rasterio.transform.from_origin(\n",
    "                lon.min(), lat.max(), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0])\n",
    "            )\n",
    "            \n",
    "            # Create a rasterio in-memory dataset\n",
    "            with rasterio.MemoryFile() as memfile:\n",
    "                with memfile.open(\n",
    "                    driver='GTiff',\n",
    "                    height=values.shape[0],\n",
    "                    width=values.shape[1],\n",
    "                    count=1,\n",
    "                    dtype=values.dtype,\n",
    "                    crs='+proj=latlong',\n",
    "                    transform=transform,\n",
    "                ) as dataset:\n",
    "                    dataset.write(values, 1)\n",
    "                    out_image, out_transform = mask(dataset, shapes, crop=True)\n",
    "                    \n",
    "                    # Convert the clipped data to xarray DataArray\n",
    "                    clipped_array = xr.DataArray(\n",
    "                        out_image[0],\n",
    "                        coords={\n",
    "                            'lat': np.arange(out_image.shape[1]),\n",
    "                            'lon': np.arange(out_image.shape[2])\n",
    "                        },\n",
    "                        dims=['lat', 'lon']\n",
    "                    )\n",
    "                    \n",
    "                    clipped_data[var] = clipped_array\n",
    "    \n",
    "    # Combine the clipped data arrays into a single dataset\n",
    "    clipped_ds = xr.Dataset(clipped_data)\n",
    "    \n",
    "    # Save the clipped dataset to a new NetCDF file\n",
    "    clipped_ds.to_netcdf(output_nc_file)\n",
    "    \n",
    "    return clipped_ds\n",
    "\n",
    "# Example usage\n",
    "nc_file = r'D:\\Git\\Projects\\Runtime files\\chirps20GlobalDailyP05_31cf_9fff_f151.nc'\n",
    "shapefile = 'D:\\Git\\Projects\\Runtime files\\LV_Kagera_Akanyaru.shp'\n",
    "output_nc_file = 'output_clipped_file.nc'\n",
    "\n",
    "clipped_ds = clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file)\n",
    "print(clipped_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8195b9cc-b989-46e0-81e6-64b14ab99ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CRS information in NetCDF file. Assuming the shapefile is already in the correct CRS.\n",
      "No variables with 'lat' and 'lon' dimensions were found and clipped.\n",
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "\n",
    "def clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file):\n",
    "    # Load the NetCDF data\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "\n",
    "    # Load the shapefile\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Ensure the shapefile is in the same coordinate reference system (CRS) as the NetCDF data\n",
    "    if 'crs' in ds.attrs:\n",
    "        crs = ds.attrs['crs']\n",
    "        gdf = gdf.to_crs(crs)\n",
    "    else:\n",
    "        print(\"No CRS information in NetCDF file. Assuming the shapefile is already in the correct CRS.\")\n",
    "\n",
    "    # Extract geometry from shapefile\n",
    "    shapes = [feature[\"geometry\"] for feature in gdf.__geo_interface__[\"features\"]]\n",
    "\n",
    "    clipped_data = {}\n",
    "\n",
    "    # Iterate over variables in the NetCDF file\n",
    "    for var in ds.data_vars:\n",
    "        data_array = ds[var]\n",
    "        \n",
    "        if 'lat' in data_array.dims and 'lon' in data_array.dims:\n",
    "            # Ensure lat and lon are sorted ascendingly\n",
    "            if data_array.lat[0] > data_array.lat[-1]:\n",
    "                data_array = data_array.reindex(lat=list(reversed(data_array.lat)))\n",
    "            if data_array.lon[0] > data_array.lon[-1]:\n",
    "                data_array = data_array.reindex(lon=list(reversed(data_array.lon)))\n",
    "                \n",
    "            lat = data_array['lat'].values\n",
    "            lon = data_array['lon'].values\n",
    "            values = data_array.values\n",
    "\n",
    "            # Define affine transform for the data array\n",
    "            transform = rasterio.transform.from_origin(\n",
    "                lon.min(), lat.max(), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0])\n",
    "            )\n",
    "            \n",
    "            # Create a rasterio in-memory dataset\n",
    "            with rasterio.MemoryFile() as memfile:\n",
    "                with memfile.open(\n",
    "                    driver='GTiff',\n",
    "                    height=values.shape[0],\n",
    "                    width=values.shape[1],\n",
    "                    count=1,\n",
    "                    dtype=values.dtype,\n",
    "                    crs='+proj=latlong',\n",
    "                    transform=transform,\n",
    "                ) as dataset:\n",
    "                    dataset.write(values, 1)\n",
    "                    out_image, out_transform = mask(dataset, shapes, crop=True)\n",
    "                    \n",
    "                    # Generate new coordinates for the clipped array\n",
    "                    new_lon = np.linspace(out_transform.c, out_transform.c + out_transform.a * out_image.shape[2], out_image.shape[2])\n",
    "                    new_lat = np.linspace(out_transform.f, out_transform.f + out_transform.e * out_image.shape[1], out_image.shape[1])\n",
    "\n",
    "                    # Convert the clipped data to xarray DataArray\n",
    "                    clipped_array = xr.DataArray(\n",
    "                        out_image[0],\n",
    "                        coords={\n",
    "                            'lat': new_lat,\n",
    "                            'lon': new_lon\n",
    "                        },\n",
    "                        dims=['lat', 'lon']\n",
    "                    )\n",
    "                    \n",
    "                    clipped_data[var] = clipped_array\n",
    "    \n",
    "    if clipped_data:\n",
    "        # Combine the clipped data arrays into a single dataset\n",
    "        clipped_ds = xr.Dataset(clipped_data)\n",
    "        \n",
    "        # Save the clipped dataset to a new NetCDF file\n",
    "        clipped_ds.to_netcdf(output_nc_file)\n",
    "    else:\n",
    "        print(\"No variables with 'lat' and 'lon' dimensions were found and clipped.\")\n",
    "        clipped_ds = xr.Dataset()\n",
    "\n",
    "    return clipped_ds\n",
    "\n",
    "# Example usage\n",
    "nc_file = r'D:\\Git\\Projects\\Runtime files\\chirps20GlobalDailyP05_31cf_9fff_f151.nc'\n",
    "shapefile = 'D:\\Git\\Projects\\Runtime files\\LV_Kagera_Akanyaru.shp'\n",
    "output_nc_file = 'output_clipped_file.nc'\n",
    "\n",
    "clipped_ds = clip_netcdf_with_shapefile(nc_file, shapefile, output_nc_file)\n",
    "print(clipped_ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
